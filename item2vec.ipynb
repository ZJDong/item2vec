{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')\n",
    "\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-11 22:55:51,067 : INFO : collecting all words and their counts\n",
      "2018-09-11 22:55:51,077 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-09-11 22:55:51,109 : INFO : PROGRESS: at sentence #10000, processed 63920 words, keeping 3151 word types\n",
      "2018-09-11 22:55:51,140 : INFO : PROGRESS: at sentence #20000, processed 129243 words, keeping 3167 word types\n",
      "2018-09-11 22:55:51,169 : INFO : PROGRESS: at sentence #30000, processed 187038 words, keeping 3167 word types\n",
      "2018-09-11 22:55:51,199 : INFO : PROGRESS: at sentence #40000, processed 242147 words, keeping 3167 word types\n",
      "2018-09-11 22:55:51,232 : INFO : PROGRESS: at sentence #50000, processed 309108 words, keeping 3167 word types\n",
      "2018-09-11 22:55:51,263 : INFO : PROGRESS: at sentence #60000, processed 378158 words, keeping 3167 word types\n",
      "2018-09-11 22:55:51,292 : INFO : PROGRESS: at sentence #70000, processed 443365 words, keeping 3167 word types\n",
      "2018-09-11 22:55:51,323 : INFO : PROGRESS: at sentence #80000, processed 501839 words, keeping 3167 word types\n",
      "2018-09-11 22:55:51,354 : INFO : PROGRESS: at sentence #90000, processed 565821 words, keeping 3167 word types\n",
      "2018-09-11 22:55:51,386 : INFO : PROGRESS: at sentence #100000, processed 629602 words, keeping 3167 word types\n",
      "2018-09-11 22:55:51,416 : INFO : PROGRESS: at sentence #110000, processed 696553 words, keeping 3167 word types\n",
      "2018-09-11 22:55:51,448 : INFO : PROGRESS: at sentence #120000, processed 755614 words, keeping 3167 word types\n",
      "2018-09-11 22:55:51,478 : INFO : PROGRESS: at sentence #130000, processed 819782 words, keeping 3167 word types\n",
      "2018-09-11 22:55:51,507 : INFO : PROGRESS: at sentence #140000, processed 875908 words, keeping 3167 word types\n",
      "2018-09-11 22:55:51,540 : INFO : PROGRESS: at sentence #150000, processed 942851 words, keeping 3167 word types\n",
      "2018-09-11 22:55:51,571 : INFO : PROGRESS: at sentence #160000, processed 1002802 words, keeping 3167 word types\n",
      "2018-09-11 22:55:51,600 : INFO : PROGRESS: at sentence #170000, processed 1061260 words, keeping 3167 word types\n",
      "2018-09-11 22:55:51,634 : INFO : PROGRESS: at sentence #180000, processed 1126745 words, keeping 3167 word types\n",
      "2018-09-11 22:55:51,682 : INFO : PROGRESS: at sentence #190000, processed 1184374 words, keeping 3167 word types\n",
      "2018-09-11 22:55:51,720 : INFO : PROGRESS: at sentence #200000, processed 1248903 words, keeping 3167 word types\n",
      "2018-09-11 22:55:51,748 : INFO : PROGRESS: at sentence #210000, processed 1309618 words, keeping 3167 word types\n",
      "2018-09-11 22:55:51,781 : INFO : PROGRESS: at sentence #220000, processed 1376636 words, keeping 3167 word types\n",
      "2018-09-11 22:55:51,809 : INFO : PROGRESS: at sentence #230000, processed 1437189 words, keeping 3167 word types\n",
      "2018-09-11 22:55:51,840 : INFO : PROGRESS: at sentence #240000, processed 1494485 words, keeping 3167 word types\n",
      "2018-09-11 22:55:51,872 : INFO : PROGRESS: at sentence #250000, processed 1553958 words, keeping 3167 word types\n",
      "2018-09-11 22:55:51,887 : INFO : collected 3167 word types from a corpus of 1580122 raw words and 254412 sentences\n",
      "2018-09-11 22:55:51,887 : INFO : Loading a fresh vocabulary\n",
      "2018-09-11 22:55:51,893 : INFO : effective_min_count=1 retains 3167 unique words (100% of original 3167, drops 0)\n",
      "2018-09-11 22:55:51,894 : INFO : effective_min_count=1 leaves 1580122 word corpus (100% of original 1580122, drops 0)\n",
      "2018-09-11 22:55:51,903 : INFO : deleting the raw counts dictionary of 3167 items\n",
      "2018-09-11 22:55:51,904 : INFO : sample=0.001 downsamples 18 most-common words\n",
      "2018-09-11 22:55:51,905 : INFO : downsampling leaves estimated 1560986 word corpus (98.8% of prior 1580122)\n",
      "2018-09-11 22:55:51,916 : INFO : estimated required memory for 3167 words and 100 dimensions: 4117100 bytes\n",
      "2018-09-11 22:55:51,918 : INFO : resetting layer weights\n",
      "2018-09-11 22:55:51,962 : INFO : training model with 3 workers on 3167 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=10\n",
      "2018-09-11 22:55:53,008 : INFO : EPOCH 1 - PROGRESS: at 25.10% examples, 378420 words/s, in_qsize 3, out_qsize 1\n",
      "2018-09-11 22:55:54,009 : INFO : EPOCH 1 - PROGRESS: at 53.37% examples, 410243 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-11 22:55:55,015 : INFO : EPOCH 1 - PROGRESS: at 77.47% examples, 397847 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-11 22:55:55,872 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-11 22:55:55,917 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-11 22:55:55,943 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-11 22:55:55,945 : INFO : EPOCH - 1 : training on 1580122 raw words (1561044 effective words) took 4.0s, 392126 effective words/s\n",
      "2018-09-11 22:55:56,977 : INFO : EPOCH 2 - PROGRESS: at 24.92% examples, 384599 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-11 22:55:57,988 : INFO : EPOCH 2 - PROGRESS: at 49.81% examples, 387516 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-11 22:55:59,027 : INFO : EPOCH 2 - PROGRESS: at 77.47% examples, 394424 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-11 22:55:59,791 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-11 22:55:59,813 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-11 22:55:59,847 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-11 22:55:59,848 : INFO : EPOCH - 2 : training on 1580122 raw words (1561003 effective words) took 3.9s, 400411 effective words/s\n",
      "2018-09-11 22:56:00,858 : INFO : EPOCH 3 - PROGRESS: at 25.67% examples, 402142 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-11 22:56:01,859 : INFO : EPOCH 3 - PROGRESS: at 53.37% examples, 417963 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-11 22:56:02,869 : INFO : EPOCH 3 - PROGRESS: at 83.11% examples, 431682 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-11 22:56:03,359 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-11 22:56:03,386 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-11 22:56:03,411 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-11 22:56:03,413 : INFO : EPOCH - 3 : training on 1580122 raw words (1561121 effective words) took 3.6s, 438304 effective words/s\n",
      "2018-09-11 22:56:04,418 : INFO : EPOCH 4 - PROGRESS: at 27.53% examples, 434097 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-11 22:56:05,442 : INFO : EPOCH 4 - PROGRESS: at 57.51% examples, 448236 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-11 22:56:06,481 : INFO : EPOCH 4 - PROGRESS: at 85.44% examples, 437921 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-11 22:56:06,882 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-11 22:56:06,916 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-11 22:56:06,945 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-11 22:56:06,946 : INFO : EPOCH - 4 : training on 1580122 raw words (1561116 effective words) took 3.5s, 442306 effective words/s\n",
      "2018-09-11 22:56:07,952 : INFO : EPOCH 5 - PROGRESS: at 26.79% examples, 423517 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-11 22:56:08,954 : INFO : EPOCH 5 - PROGRESS: at 56.50% examples, 443278 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-11 22:56:09,965 : INFO : EPOCH 5 - PROGRESS: at 88.01% examples, 458263 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-11 22:56:10,288 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-11 22:56:10,320 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-11 22:56:10,346 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-11 22:56:10,347 : INFO : EPOCH - 5 : training on 1580122 raw words (1561140 effective words) took 3.4s, 459510 effective words/s\n",
      "2018-09-11 22:56:11,369 : INFO : EPOCH 6 - PROGRESS: at 28.67% examples, 445195 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-11 22:56:12,404 : INFO : EPOCH 6 - PROGRESS: at 59.37% examples, 456220 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-11 22:56:13,422 : INFO : EPOCH 6 - PROGRESS: at 91.31% examples, 465543 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-11 22:56:13,622 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-11 22:56:13,658 : INFO : worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-11 22:56:13,673 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-11 22:56:13,674 : INFO : EPOCH - 6 : training on 1580122 raw words (1560723 effective words) took 3.3s, 469363 effective words/s\n",
      "2018-09-11 22:56:14,710 : INFO : EPOCH 7 - PROGRESS: at 28.67% examples, 440455 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-11 22:56:15,722 : INFO : EPOCH 7 - PROGRESS: at 54.66% examples, 420109 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-11 22:56:16,740 : INFO : EPOCH 7 - PROGRESS: at 85.59% examples, 438404 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-11 22:56:17,151 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-11 22:56:17,192 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-11 22:56:17,206 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-11 22:56:17,207 : INFO : EPOCH - 7 : training on 1580122 raw words (1560865 effective words) took 3.5s, 442270 effective words/s\n",
      "2018-09-11 22:56:18,251 : INFO : EPOCH 8 - PROGRESS: at 30.61% examples, 465397 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-11 22:56:19,253 : INFO : EPOCH 8 - PROGRESS: at 61.04% examples, 473668 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-11 22:56:20,254 : INFO : EPOCH 8 - PROGRESS: at 92.66% examples, 476587 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-11 22:56:20,414 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-11 22:56:20,427 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-11 22:56:20,471 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-11 22:56:20,472 : INFO : EPOCH - 8 : training on 1580122 raw words (1560959 effective words) took 3.3s, 478697 effective words/s\n",
      "2018-09-11 22:56:21,503 : INFO : EPOCH 9 - PROGRESS: at 30.61% examples, 470320 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-11 22:56:22,509 : INFO : EPOCH 9 - PROGRESS: at 61.96% examples, 480014 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-11 22:56:23,518 : INFO : EPOCH 9 - PROGRESS: at 93.83% examples, 483098 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-11 22:56:23,652 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-11 22:56:23,663 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-11 22:56:23,701 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-11 22:56:23,702 : INFO : EPOCH - 9 : training on 1580122 raw words (1561028 effective words) took 3.2s, 483564 effective words/s\n",
      "2018-09-11 22:56:24,736 : INFO : EPOCH 10 - PROGRESS: at 28.67% examples, 439869 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-11 22:56:25,754 : INFO : EPOCH 10 - PROGRESS: at 57.51% examples, 443001 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-11 22:56:26,758 : INFO : EPOCH 10 - PROGRESS: at 87.45% examples, 449136 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-11 22:56:27,081 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-11 22:56:27,094 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-11 22:56:27,128 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-11 22:56:27,129 : INFO : EPOCH - 10 : training on 1580122 raw words (1560971 effective words) took 3.4s, 455788 effective words/s\n",
      "2018-09-11 22:56:27,129 : INFO : training on a 15801220 raw words (15609970 effective words) took 35.2s, 443888 effective words/s\n",
      "2018-09-11 22:56:27,130 : INFO : saving Word2Vec object under item2vec.model, separately None\n",
      "2018-09-11 22:56:27,131 : INFO : not storing attribute vectors_norm\n",
      "2018-09-11 22:56:27,132 : INFO : not storing attribute cum_table\n",
      "2018-09-11 22:56:27,193 : INFO : saved item2vec.model\n"
     ]
    }
   ],
   "source": [
    "# Open data file\n",
    "file = open('./dataset/yes_i2v/train2.txt','r')\n",
    "playlists = word2vec.LineSentence(file)\n",
    "\n",
    "#\n",
    "path = get_tmpfile(\"item2vec.model\")\n",
    "    \n",
    "# Modelling\n",
    "model = word2vec.Word2Vec(playlists, sg=1, min_count=1, window=10, iter=10, size=100)\n",
    "model.save(\"item2vec.model\")\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting similar items by name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-11 22:56:33,898 : INFO : precomputing L2-norms of word weight vectors\n",
      "D:\\Development\\Anaconda3\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('2610', 0.9918410778045654),\n",
       " ('3115', 0.9901841282844543),\n",
       " ('1110', 0.98928302526474),\n",
       " ('1106', 0.988652229309082),\n",
       " ('2777', 0.9873285293579102),\n",
       " ('1108', 0.9860349297523499),\n",
       " ('2801', 0.9849622249603271),\n",
       " ('3027', 0.9832320213317871),\n",
       " ('1107', 0.9832187294960022),\n",
       " ('3028', 0.980350136756897),\n",
       " ('1077', 0.9749118685722351),\n",
       " ('1072', 0.9734851121902466),\n",
       " ('105', 0.9733776450157166),\n",
       " ('1070', 0.9730795621871948),\n",
       " ('1041', 0.9713771343231201),\n",
       " ('1079', 0.9712492227554321),\n",
       " ('1087', 0.9678834080696106),\n",
       " ('1062', 0.9653787016868591),\n",
       " ('1037', 0.9644817113876343),\n",
       " ('1066', 0.9640263915061951)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_word('3029', topn =20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Development\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           x         y\n",
      "0 -48.885067  5.443846\n",
      "1 -44.316376 -5.828230\n",
      "2 -52.608604  2.166635\n",
      "3 -48.853947 -2.362439\n",
      "4 -49.298435 -2.150290\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "\n",
    "vocab = list(model.wv.vocab)\n",
    "X = model[vocab]\n",
    "\n",
    "tsne = TSNE(n_components=2)\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "\n",
    "df = pd.DataFrame(X_tsne, index=vocab, columns=['x', 'y'])\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              x         y\n",
      "3    -48.853947 -2.362439\n",
      "1744 -42.078548  1.058095\n",
      "79   -42.875626 -5.258737\n"
     ]
    }
   ],
   "source": [
    "# Representative points\n",
    "# usher\n",
    "df2 = df.loc[['3', '1744','79']]\n",
    "\n",
    "# Guns'n rose\n",
    "df3 = df.loc[['318', '365','314']]\n",
    "\n",
    "# Bob Marley\n",
    "df4 = df.loc[['1040', '3029','1110']]\n",
    "\n",
    "# Fall out boys\n",
    "df5 = df.loc[['2641', '2966','2348']]\n",
    "\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "x   -48.853947\n",
      "y    -2.362439\n",
      "Name: 3, dtype: float32\n",
      "x   -42.078548\n",
      "y     1.058095\n",
      "Name: 1744, dtype: float32\n",
      "x   -42.875626\n",
      "y    -5.258737\n",
      "Name: 79, dtype: float32\n",
      "x    23.850960\n",
      "y   -36.922859\n",
      "Name: 318, dtype: float32\n",
      "x    28.731955\n",
      "y   -40.050190\n",
      "Name: 365, dtype: float32\n",
      "x    28.174059\n",
      "y   -15.112495\n",
      "Name: 314, dtype: float32\n",
      "x    -1.294396\n",
      "y    64.735275\n",
      "Name: 1040, dtype: float32\n",
      "x     4.238662\n",
      "y    70.469826\n",
      "Name: 3029, dtype: float32\n",
      "x     5.145927\n",
      "y    71.447586\n",
      "Name: 1110, dtype: float32\n",
      "x   -19.509104\n",
      "y    -8.304080\n",
      "Name: 2641, dtype: float32\n",
      "x   -15.760060\n",
      "y   -12.127275\n",
      "Name: 2966, dtype: float32\n",
      "x   -19.897903\n",
      "y    -9.086158\n",
      "Name: 2348, dtype: float32\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "x = df['x']\n",
    "y = df['y']\n",
    "\n",
    "# Calculate the point density\n",
    "xy = np.vstack([x,y])\n",
    "z = gaussian_kde(xy)(xy)\n",
    "\n",
    "# Plot a scatter\n",
    "ax.scatter(x, y, c=z, s=10, edgecolor='')\n",
    "\n",
    "#\n",
    "for i,pos in df2.iterrows():\n",
    "    print(pos)\n",
    "    ax.plot(pos[0],pos[1],'m^')\n",
    "\n",
    "#\n",
    "for i,pos in df3.iterrows():\n",
    "    print(pos)\n",
    "    ax.plot(pos[0],pos[1],'bv')\n",
    "    \n",
    "#\n",
    "for i,pos in df4.iterrows():\n",
    "    print(pos)\n",
    "    ax.plot(pos[0],pos[1],'yD')\n",
    "\n",
    "#\n",
    "for i,pos in df5.iterrows():\n",
    "    print(pos)\n",
    "    ax.plot(pos[0],pos[1],'rx')\n",
    "    \n",
    "# # Show annotating of items in df2\n",
    "# for word, pos in df2.iterrows():\n",
    "#     ax.annotate(word, pos)\n",
    "# for word, pos in df3.iterrows():\n",
    "#     ax.annotate(word, pos)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use of genre data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Num                                         Music Name      Artist  \\\n",
      "0    0                       Gucci Time (w\\/ Swizz Beatz)  Gucci Mane   \n",
      "1    1  Aston Martin Music (w\\/ Drake & Chrisette Mich...   Rick Ross   \n",
      "2    2                      Get Back Up (w\\/ Chris Brown)        T.I.   \n",
      "3    3                 Hot Toddy (w\\/ Jay-Z & Ester Dean)       Usher   \n",
      "4    4                                       Whip My Hair      Willow   \n",
      "\n",
      "                                             Tags  \n",
      "0                                         115 173  \n",
      "1      14 27 62 88 90 110 115 123 155 173 190 214  \n",
      "2                                         115 173  \n",
      "3                                        2 72 173  \n",
      "4  2 6 24 52 62 72 88 107 115 126 141 155 173 190   \n",
      "\n",
      "Searching Music:  1040 \t Three Little Birds \t Bob Marley & The Wailers \n",
      "\n",
      "Similar Music:  One Love \\/ People Get Ready \t Bob Marley & The Wailers\n",
      "('1059', 0.9395015835762024)\n",
      "Similar Music:  Is This Love? \t Bob Marley & The Wailers\n",
      "('1099', 0.9298379421234131)\n",
      "Similar Music:  Buffalo Soldier \t Bob Marley & The Wailers\n",
      "('1083', 0.9173524975776672)\n",
      "Similar Music:  Could You Be Loved \t Bob Marley & The Wailers\n",
      "('1085', 0.913905143737793)\n",
      "Similar Music:  Jamming \t Bob Marley & The Wailers\n",
      "('1078', 0.9135004281997681)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Development\\Anaconda3\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "import pandas as pd\n",
    "\n",
    "df_sum = pd.read_table(\"./dataset/yes_i2v/summary.txt\", delimiter='\\t', header=None, names=('Num', 'Music Name', 'Artist', 'Tags'))\n",
    "print(df_sum.head(),'\\n')\n",
    "\n",
    "# Print similiraties by number of music\n",
    "def print_simi(music_num):\n",
    "    simi_list = model.wv.similar_by_word(str(music_num), topn =5)\n",
    "    print(\"Searching Music: \",music_num, '\\t',df_sum.iat[music_num, 1], '\\t',df_sum.iat[music_num, 2], \"\\n\")\n",
    "    for l in simi_list:\n",
    "        print(\"Similar Music: \", df_sum.iat[int(l[0]), 1], '\\t',df_sum.iat[int(l[0]), 2])\n",
    "        print(l)\n",
    "\n",
    "        \n",
    "print_simi(1040)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['50', '62', '72', '88', '90', '98', '115', '88', '115', '155', '173', '90', '115', '155', '173', '250'] \n",
      "\n",
      "([('115', 3), ('88', 2), ('90', 2), ('155', 2)], [' wjlb-fm', ' hip hop', ' rap', ' wkqi-fm'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Development\\Anaconda3\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([('115', 3), ('88', 2), ('90', 2)], [' wjlb-fm', ' hip hop', ' rap'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "df_tag = pd.read_table(\"./dataset/yes_small/tag_hash.txt\", delimiter=',', header=None, names=('Num', 'Tag'))\n",
    "\n",
    "# Get tags of all of five similar musics\n",
    "def get_tags(music_num):\n",
    "    simi_list = model.wv.similar_by_word(str(music_num), topn =5)\n",
    "    tags = []\n",
    "    for l in simi_list:\n",
    "        tags_str = df_sum.iat[int(l[0]), 3]\n",
    "        tags_list = tags_str.split()\n",
    "        for i in tags_list:\n",
    "            tags.append(i)\n",
    "    return(tags)\n",
    "    \n",
    "print(get_tags(8),'\\n')\n",
    "\n",
    "# Get top n of common tags in five similar musics\n",
    "def top_n_tags(music_num, topn=3):\n",
    "    tags = get_tags(music_num)\n",
    "    tags_counts = Counter(tags)\n",
    "    top_n = tags_counts.most_common(topn)\n",
    "    top_n_tag_name = []\n",
    "    for i in top_n:\n",
    "        top_n_tag_name.append(df_tag.iat[int(i[0]),1])\n",
    "#         print(df_tag.iat[int(i[0]),1])\n",
    "#     for j in top_n:\n",
    "#         times.append(j[1])\n",
    "    return top_n, top_n_tag_name\n",
    "\n",
    "print(top_n_tags(8,topn=4))  \n",
    "top_n_tags(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching Music:  2519 \t Watching Airplanes \t Gary Allan \n",
      "\n",
      "Similar Music:  Good Morning Beautiful \t Steve Holy\n",
      "('513', 0.9254266619682312)\n",
      "Similar Music:  International Harvester \t Craig Morgan\n",
      "('1888', 0.9051247835159302)\n",
      "Similar Music:  Something To Be Proud Of \t Montgomery Gentry\n",
      "('481', 0.9023962616920471)\n",
      "Similar Music:  Lesson In Leavin' \t Jo Dee Messina\n",
      "('586', 0.9023303389549255)\n",
      "Similar Music:  Free And Easy (Down The Road I Go) \t Dierks Bentley\n",
      "('479', 0.8975435495376587)\n",
      "\n",
      "\n",
      "Top N common tags:  [' country', ' 00s', ' good song']\n",
      "Appearance times of common tags:  [4, 3, 2] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Development\\Anaconda3\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "def genre_of_simis(music_num):\n",
    "    print_simi(music_num)\n",
    "    print('\\n')\n",
    "    print(\"Top N common tags: \",top_n_tags(music_num)[1])\n",
    "    times = []\n",
    "    for i in top_n_tags(music_num)[0]:\n",
    "        times.append(i[1])\n",
    "    print(\"Appearance times of common tags: \", times,'\\n')\n",
    "    \n",
    "    \n",
    "genre_of_simis(2519)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing rec-music's tags with searching-music's tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Development\\Anaconda3\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9071383449147189\n"
     ]
    }
   ],
   "source": [
    "def cal_common_tags(music_num):\n",
    "    tags_str = df_sum.iat[music_num, 3]\n",
    "    tags_list = tags_str.split()\n",
    "    list_a = []\n",
    "    for i in tags_list:\n",
    "        list_a.append(i)\n",
    "#     print(list_a)\n",
    "    #\n",
    "    list_b = []\n",
    "    top_n = top_n_tags(music_num, topn=5)[0]\n",
    "    for j in top_n:\n",
    "        list_b.append(j[0])\n",
    "#     print(list_b,'\\n')\n",
    "    #\n",
    "    result = list(set(list_a) & set(list_b))\n",
    "    if len(result):    # not empty\n",
    "#         print(result)\n",
    "#         print('true')\n",
    "        return 1\n",
    "    else:\n",
    "#         print('false')\n",
    "        return 0\n",
    "        \n",
    "\n",
    "def cal_acc():\n",
    "    tf_list = []\n",
    "    for i in range(0, 2015):\n",
    "#         print(i)\n",
    "        tf_list.append(cal_common_tags(i))\n",
    "    for j in range(2016, 3167):\n",
    "#         print(j)\n",
    "        tf_list.append(cal_common_tags(j))\n",
    "    total = len(tf_list)\n",
    "    right_count =[]\n",
    "    for i in tf_list:\n",
    "        if i ==1:\n",
    "            right_count.append(i)\n",
    "    right = len(right_count)\n",
    "    print(right/total)\n",
    "\n",
    "    \n",
    "cal_acc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "item2vec",
   "language": "python",
   "name": "item2vec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
