{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')\n",
    "\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-07 14:01:19,132 : INFO : collecting all words and their counts\n",
      "2018-09-07 14:01:19,133 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-09-07 14:01:19,171 : INFO : PROGRESS: at sentence #10000, processed 63920 words, keeping 3151 word types\n",
      "2018-09-07 14:01:19,203 : INFO : PROGRESS: at sentence #20000, processed 129243 words, keeping 3167 word types\n",
      "2018-09-07 14:01:19,232 : INFO : PROGRESS: at sentence #30000, processed 187038 words, keeping 3167 word types\n",
      "2018-09-07 14:01:19,259 : INFO : PROGRESS: at sentence #40000, processed 242147 words, keeping 3167 word types\n",
      "2018-09-07 14:01:19,289 : INFO : PROGRESS: at sentence #50000, processed 309108 words, keeping 3167 word types\n",
      "2018-09-07 14:01:19,320 : INFO : PROGRESS: at sentence #60000, processed 378158 words, keeping 3167 word types\n",
      "2018-09-07 14:01:19,348 : INFO : PROGRESS: at sentence #70000, processed 443365 words, keeping 3167 word types\n",
      "2018-09-07 14:01:19,378 : INFO : PROGRESS: at sentence #80000, processed 501839 words, keeping 3167 word types\n",
      "2018-09-07 14:01:19,407 : INFO : PROGRESS: at sentence #90000, processed 565821 words, keeping 3167 word types\n",
      "2018-09-07 14:01:19,438 : INFO : PROGRESS: at sentence #100000, processed 629602 words, keeping 3167 word types\n",
      "2018-09-07 14:01:19,472 : INFO : PROGRESS: at sentence #110000, processed 696553 words, keeping 3167 word types\n",
      "2018-09-07 14:01:19,498 : INFO : PROGRESS: at sentence #120000, processed 755614 words, keeping 3167 word types\n",
      "2018-09-07 14:01:19,528 : INFO : PROGRESS: at sentence #130000, processed 819782 words, keeping 3167 word types\n",
      "2018-09-07 14:01:19,554 : INFO : PROGRESS: at sentence #140000, processed 875908 words, keeping 3167 word types\n",
      "2018-09-07 14:01:19,591 : INFO : PROGRESS: at sentence #150000, processed 942851 words, keeping 3167 word types\n",
      "2018-09-07 14:01:19,618 : INFO : PROGRESS: at sentence #160000, processed 1002802 words, keeping 3167 word types\n",
      "2018-09-07 14:01:19,648 : INFO : PROGRESS: at sentence #170000, processed 1061260 words, keeping 3167 word types\n",
      "2018-09-07 14:01:19,682 : INFO : PROGRESS: at sentence #180000, processed 1126745 words, keeping 3167 word types\n",
      "2018-09-07 14:01:19,712 : INFO : PROGRESS: at sentence #190000, processed 1184374 words, keeping 3167 word types\n",
      "2018-09-07 14:01:19,744 : INFO : PROGRESS: at sentence #200000, processed 1248903 words, keeping 3167 word types\n",
      "2018-09-07 14:01:19,776 : INFO : PROGRESS: at sentence #210000, processed 1309618 words, keeping 3167 word types\n",
      "2018-09-07 14:01:19,811 : INFO : PROGRESS: at sentence #220000, processed 1376636 words, keeping 3167 word types\n",
      "2018-09-07 14:01:19,840 : INFO : PROGRESS: at sentence #230000, processed 1437189 words, keeping 3167 word types\n",
      "2018-09-07 14:01:19,873 : INFO : PROGRESS: at sentence #240000, processed 1494485 words, keeping 3167 word types\n",
      "2018-09-07 14:01:19,903 : INFO : PROGRESS: at sentence #250000, processed 1553958 words, keeping 3167 word types\n",
      "2018-09-07 14:01:19,916 : INFO : collected 3167 word types from a corpus of 1580122 raw words and 254412 sentences\n",
      "2018-09-07 14:01:19,917 : INFO : Loading a fresh vocabulary\n",
      "2018-09-07 14:01:19,923 : INFO : effective_min_count=1 retains 3167 unique words (100% of original 3167, drops 0)\n",
      "2018-09-07 14:01:19,925 : INFO : effective_min_count=1 leaves 1580122 word corpus (100% of original 1580122, drops 0)\n",
      "2018-09-07 14:01:19,936 : INFO : deleting the raw counts dictionary of 3167 items\n",
      "2018-09-07 14:01:19,938 : INFO : sample=0.001 downsamples 18 most-common words\n",
      "2018-09-07 14:01:19,938 : INFO : downsampling leaves estimated 1560986 word corpus (98.8% of prior 1580122)\n",
      "2018-09-07 14:01:19,949 : INFO : estimated required memory for 3167 words and 100 dimensions: 4117100 bytes\n",
      "2018-09-07 14:01:19,951 : INFO : resetting layer weights\n",
      "2018-09-07 14:01:19,999 : INFO : training model with 3 workers on 3167 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=3\n",
      "2018-09-07 14:01:21,002 : INFO : EPOCH 1 - PROGRESS: at 72.24% examples, 1134735 words/s, in_qsize 1, out_qsize 0\n",
      "2018-09-07 14:01:21,416 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-07 14:01:21,422 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-07 14:01:21,431 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-07 14:01:21,433 : INFO : EPOCH - 1 : training on 1580122 raw words (1561137 effective words) took 1.4s, 1091158 effective words/s\n",
      "2018-09-07 14:01:22,457 : INFO : EPOCH 2 - PROGRESS: at 70.27% examples, 1083245 words/s, in_qsize 6, out_qsize 0\n",
      "2018-09-07 14:01:22,763 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-07 14:01:22,767 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-07 14:01:22,775 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-07 14:01:22,776 : INFO : EPOCH - 2 : training on 1580122 raw words (1560872 effective words) took 1.3s, 1164971 effective words/s\n",
      "2018-09-07 14:01:23,782 : INFO : EPOCH 3 - PROGRESS: at 77.98% examples, 1221643 words/s, in_qsize 0, out_qsize 0\n",
      "2018-09-07 14:01:24,127 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-07 14:01:24,132 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-07 14:01:24,136 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-07 14:01:24,137 : INFO : EPOCH - 3 : training on 1580122 raw words (1560921 effective words) took 1.4s, 1150359 effective words/s\n",
      "2018-09-07 14:01:25,140 : INFO : EPOCH 4 - PROGRESS: at 72.24% examples, 1134171 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-07 14:01:25,515 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-07 14:01:25,517 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-07 14:01:25,521 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-07 14:01:25,522 : INFO : EPOCH - 4 : training on 1580122 raw words (1560884 effective words) took 1.4s, 1129329 effective words/s\n",
      "2018-09-07 14:01:26,526 : INFO : EPOCH 5 - PROGRESS: at 74.31% examples, 1162981 words/s, in_qsize 2, out_qsize 0\n",
      "2018-09-07 14:01:26,889 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-07 14:01:26,891 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-07 14:01:26,904 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-07 14:01:26,906 : INFO : EPOCH - 5 : training on 1580122 raw words (1560850 effective words) took 1.4s, 1129511 effective words/s\n",
      "2018-09-07 14:01:26,908 : INFO : training on a 7900610 raw words (7804664 effective words) took 6.9s, 1129615 effective words/s\n",
      "2018-09-07 14:01:26,910 : INFO : saving Word2Vec object under item2vec_cwob.model, separately None\n",
      "2018-09-07 14:01:26,912 : INFO : not storing attribute vectors_norm\n",
      "2018-09-07 14:01:26,914 : INFO : not storing attribute cum_table\n",
      "2018-09-07 14:01:26,952 : INFO : saved item2vec_cwob.model\n"
     ]
    }
   ],
   "source": [
    "# Open data file\n",
    "file = open('./dataset/yes_i2v/train2.txt','r')\n",
    "playlists = word2vec.LineSentence(file)\n",
    "\n",
    "#\n",
    "path = get_tmpfile(\"item2vec_cwob.model\")\n",
    "    \n",
    "# Modelling\n",
    "model = word2vec.Word2Vec(playlists, sg=0, min_count=1, window=3, size=100)\n",
    "model.save(\"item2vec_cwob.model\")\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting similar items by name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-07 13:55:53,313 : INFO : precomputing L2-norms of word weight vectors\n",
      "D:\\Development\\Anaconda3\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('275', 0.9521846771240234),\n",
       " ('944', 0.9515206813812256),\n",
       " ('249', 0.9510353803634644),\n",
       " ('351', 0.9506646394729614),\n",
       " ('910', 0.9496343731880188)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_word('318', topn =5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Development\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          x          y\n",
      "0 -5.287024 -37.210419\n",
      "1  4.939063 -37.333065\n",
      "2 -3.599873 -41.143066\n",
      "3  3.098632 -37.629406\n",
      "4  2.545206 -38.217239\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "\n",
    "vocab = list(model.wv.vocab)\n",
    "X = model[vocab]\n",
    "\n",
    "tsne = TSNE(n_components=2)\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "\n",
    "df = pd.DataFrame(X_tsne, index=vocab, columns=['x', 'y'])\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             x          y\n",
      "318  35.744228  24.436533\n",
      "253  39.397102  26.565302\n",
      "910  37.439102  28.336428\n"
     ]
    }
   ],
   "source": [
    "# Representative points\n",
    "# Guns'n rose\n",
    "df2 = df.loc[['318', '253','910']]\n",
    "print(df2)\n",
    "# Usher\n",
    "df3 = df.loc[['3', '1669','2779']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "x = df['x']\n",
    "y = df['y']\n",
    "\n",
    "# Calculate the point density\n",
    "xy = np.vstack([x,y])\n",
    "z = gaussian_kde(xy)(xy)\n",
    "\n",
    "# Plot a scatter\n",
    "ax.scatter(x, y, c=z, s=10, edgecolor='')\n",
    "\n",
    "# Show annotating of items in df2\n",
    "for word, pos in df2.iterrows():\n",
    "    ax.annotate(word, pos)\n",
    "for word, pos in df3.iterrows():\n",
    "    ax.annotate(word, pos)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use of genre data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Num                                         Music Name      Artist  \\\n",
      "0    0                       Gucci Time (w\\/ Swizz Beatz)  Gucci Mane   \n",
      "1    1  Aston Martin Music (w\\/ Drake & Chrisette Mich...   Rick Ross   \n",
      "2    2                      Get Back Up (w\\/ Chris Brown)        T.I.   \n",
      "3    3                 Hot Toddy (w\\/ Jay-Z & Ester Dean)       Usher   \n",
      "4    4                                       Whip My Hair      Willow   \n",
      "\n",
      "                                             Tags  \n",
      "0                                         115 173  \n",
      "1      14 27 62 88 90 110 115 123 155 173 190 214  \n",
      "2                                         115 173  \n",
      "3                                        2 72 173  \n",
      "4  2 6 24 52 62 72 88 107 115 126 141 155 173 190   \n",
      "\n",
      "Searching Music:  1040 \t Three Little Birds \t Bob Marley & The Wailers \n",
      "\n",
      "Similar Music:  Is This Love? \t Bob Marley & The Wailers\n",
      "('1099', 0.9869982004165649)\n",
      "Similar Music:  Buffalo Soldier \t Bob Marley & The Wailers\n",
      "('1083', 0.9839478135108948)\n",
      "Similar Music:  No Woman No Cry \t Bob Marley & The Wailers\n",
      "('1096', 0.9812123775482178)\n",
      "Similar Music:  Stir It Up \t Bob Marley & The Wailers\n",
      "('1081', 0.9780142307281494)\n",
      "Similar Music:  One Love \\/ People Get Ready \t Bob Marley & The Wailers\n",
      "('1059', 0.9747987985610962)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\development\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "import pandas as pd\n",
    "\n",
    "df_sum = pd.read_table(\"./dataset/yes_i2v/summary.txt\", delimiter='\\t', header=None, names=('Num', 'Music Name', 'Artist', 'Tags'))\n",
    "print(df_sum.head(),'\\n')\n",
    "\n",
    "# Print similiraties by number of music\n",
    "def print_simi(music_num):\n",
    "    simi_list = model.wv.similar_by_word(str(music_num), topn =5)\n",
    "    print(\"Searching Music: \",music_num, '\\t',df_sum.iat[music_num, 1], '\\t',df_sum.iat[music_num, 2], \"\\n\")\n",
    "    for l in simi_list:\n",
    "        print(\"Similar Music: \", df_sum.iat[int(l[0]), 1], '\\t',df_sum.iat[int(l[0]), 2])\n",
    "        print(l)\n",
    "\n",
    "        \n",
    "print_simi(1040)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['88', '50', '62', '72', '88', '90', '98', '115', '115', '173', '115', '6', '52', '56', '62', '66', '98', '106', '115', '148', '173'] \n",
      "\n",
      "([('115', 4), ('173', 2), ('62', 2), ('88', 2)], [' wjlb-fm', ' whtd-fm', ' rnb', ' hip hop'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\development\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([('115', 4), ('173', 2), ('62', 2)], [' wjlb-fm', ' whtd-fm', ' rnb'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "df_tag = pd.read_table(\"./dataset/yes_small/tag_hash.txt\", delimiter=',', header=None, names=('Num', 'Tag'))\n",
    "\n",
    "# Get tags of all of five similar musics\n",
    "def get_tags(music_num):\n",
    "    simi_list = model.wv.similar_by_word(str(music_num), topn =5)\n",
    "    tags = []\n",
    "    for l in simi_list:\n",
    "        tags_str = df_sum.iat[int(l[0]), 3]\n",
    "        tags_list = tags_str.split()\n",
    "        for i in tags_list:\n",
    "            tags.append(i)\n",
    "    return(tags)\n",
    "    \n",
    "print(get_tags(8),'\\n')\n",
    "\n",
    "# Get top n of common tags in five similar musics\n",
    "def top_n_tags(music_num, topn=3):\n",
    "    tags = get_tags(music_num)\n",
    "    tags_counts = Counter(tags)\n",
    "    top_n = tags_counts.most_common(topn)\n",
    "    top_n_tag_name = []\n",
    "    for i in top_n:\n",
    "        top_n_tag_name.append(df_tag.iat[int(i[0]),1])\n",
    "#         print(df_tag.iat[int(i[0]),1])\n",
    "#     for j in top_n:\n",
    "#         times.append(j[1])\n",
    "    return top_n, top_n_tag_name\n",
    "\n",
    "print(top_n_tags(8,topn=4))  \n",
    "top_n_tags(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching Music:  32 \t Boom Boom Pow \t Black Eyed Peas \n",
      "\n",
      "Similar Music:  Sweet Dreams \t Beyonce\n",
      "('1678', 0.9812947511672974)\n",
      "Similar Music:  Replay \t Sean Kingston\n",
      "('1677', 0.9747378826141357)\n",
      "Similar Music:  Sexy Chick (w\\/ Akon) \t David Guetta\n",
      "('1694', 0.9737188816070557)\n",
      "Similar Music:  Whatcha Say \t Jason DeRulo\n",
      "('71', 0.9686710834503174)\n",
      "Similar Music:  Telephone (w\\/ Beyonce) \t Lady Gaga\n",
      "('1693', 0.9615379571914673)\n",
      "\n",
      "\n",
      "Top N common tags:  [' rnb', ' pop', ' catchy']\n",
      "Appearance times of common tags:  [5, 4, 4] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\development\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "def genre_of_simis(music_num):\n",
    "    print_simi(music_num)\n",
    "    print('\\n')\n",
    "    print(\"Top N common tags: \",top_n_tags(music_num)[1])\n",
    "    times = []\n",
    "    for i in top_n_tags(music_num)[0]:\n",
    "        times.append(i[1])\n",
    "    print(\"Appearance times of common tags: \", times,'\\n')\n",
    "    \n",
    "    \n",
    "genre_of_simis(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing rec-music's tags with searching-music's tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\development\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9055590650663298\n"
     ]
    }
   ],
   "source": [
    "def cal_common_tags(music_num):\n",
    "    tags_str = df_sum.iat[music_num, 3]\n",
    "    tags_list = tags_str.split()\n",
    "    list_a = []\n",
    "    for i in tags_list:\n",
    "        list_a.append(i)\n",
    "#     print(list_a)\n",
    "    #\n",
    "    list_b = []\n",
    "    top_n = top_n_tags(music_num, topn=5)[0]\n",
    "    for j in top_n:\n",
    "        list_b.append(j[0])\n",
    "#     print(list_b,'\\n')\n",
    "    #\n",
    "    result = list(set(list_a) & set(list_b))\n",
    "    if len(result):    # not empty\n",
    "#         print(result)\n",
    "#         print('true')\n",
    "        return 1\n",
    "    else:\n",
    "#         print('false')\n",
    "        return 0\n",
    "        \n",
    "\n",
    "def cal_acc():\n",
    "    tf_list = []\n",
    "    for i in range(0, 2015):\n",
    "#         print(i)\n",
    "        tf_list.append(cal_common_tags(i))\n",
    "    for j in range(2016, 3167):\n",
    "#         print(j)\n",
    "        tf_list.append(cal_common_tags(j))\n",
    "    total = len(tf_list)\n",
    "    right_count =[]\n",
    "    for i in tf_list:\n",
    "        if i ==1:\n",
    "            right_count.append(i)\n",
    "    right = len(right_count)\n",
    "    print(right/total)\n",
    "\n",
    "    \n",
    "cal_acc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "item2vec",
   "language": "python",
   "name": "item2vec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
