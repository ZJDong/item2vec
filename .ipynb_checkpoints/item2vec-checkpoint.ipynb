{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')\n",
    "\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-08 14:48:16,334 : INFO : collecting all words and their counts\n",
      "2018-09-08 14:48:16,335 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-09-08 14:48:16,366 : INFO : PROGRESS: at sentence #10000, processed 63920 words, keeping 3151 word types\n",
      "2018-09-08 14:48:16,400 : INFO : PROGRESS: at sentence #20000, processed 129243 words, keeping 3167 word types\n",
      "2018-09-08 14:48:16,426 : INFO : PROGRESS: at sentence #30000, processed 187038 words, keeping 3167 word types\n",
      "2018-09-08 14:48:16,459 : INFO : PROGRESS: at sentence #40000, processed 242147 words, keeping 3167 word types\n",
      "2018-09-08 14:48:16,489 : INFO : PROGRESS: at sentence #50000, processed 309108 words, keeping 3167 word types\n",
      "2018-09-08 14:48:16,522 : INFO : PROGRESS: at sentence #60000, processed 378158 words, keeping 3167 word types\n",
      "2018-09-08 14:48:16,553 : INFO : PROGRESS: at sentence #70000, processed 443365 words, keeping 3167 word types\n",
      "2018-09-08 14:48:16,579 : INFO : PROGRESS: at sentence #80000, processed 501839 words, keeping 3167 word types\n",
      "2018-09-08 14:48:16,610 : INFO : PROGRESS: at sentence #90000, processed 565821 words, keeping 3167 word types\n",
      "2018-09-08 14:48:16,643 : INFO : PROGRESS: at sentence #100000, processed 629602 words, keeping 3167 word types\n",
      "2018-09-08 14:48:16,675 : INFO : PROGRESS: at sentence #110000, processed 696553 words, keeping 3167 word types\n",
      "2018-09-08 14:48:16,705 : INFO : PROGRESS: at sentence #120000, processed 755614 words, keeping 3167 word types\n",
      "2018-09-08 14:48:16,731 : INFO : PROGRESS: at sentence #130000, processed 819782 words, keeping 3167 word types\n",
      "2018-09-08 14:48:16,760 : INFO : PROGRESS: at sentence #140000, processed 875908 words, keeping 3167 word types\n",
      "2018-09-08 14:48:16,795 : INFO : PROGRESS: at sentence #150000, processed 942851 words, keeping 3167 word types\n",
      "2018-09-08 14:48:16,823 : INFO : PROGRESS: at sentence #160000, processed 1002802 words, keeping 3167 word types\n",
      "2018-09-08 14:48:16,856 : INFO : PROGRESS: at sentence #170000, processed 1061260 words, keeping 3167 word types\n",
      "2018-09-08 14:48:16,889 : INFO : PROGRESS: at sentence #180000, processed 1126745 words, keeping 3167 word types\n",
      "2018-09-08 14:48:16,915 : INFO : PROGRESS: at sentence #190000, processed 1184374 words, keeping 3167 word types\n",
      "2018-09-08 14:48:16,945 : INFO : PROGRESS: at sentence #200000, processed 1248903 words, keeping 3167 word types\n",
      "2018-09-08 14:48:16,978 : INFO : PROGRESS: at sentence #210000, processed 1309618 words, keeping 3167 word types\n",
      "2018-09-08 14:48:17,007 : INFO : PROGRESS: at sentence #220000, processed 1376636 words, keeping 3167 word types\n",
      "2018-09-08 14:48:17,038 : INFO : PROGRESS: at sentence #230000, processed 1437189 words, keeping 3167 word types\n",
      "2018-09-08 14:48:17,071 : INFO : PROGRESS: at sentence #240000, processed 1494485 words, keeping 3167 word types\n",
      "2018-09-08 14:48:17,101 : INFO : PROGRESS: at sentence #250000, processed 1553958 words, keeping 3167 word types\n",
      "2018-09-08 14:48:17,113 : INFO : collected 3167 word types from a corpus of 1580122 raw words and 254412 sentences\n",
      "2018-09-08 14:48:17,114 : INFO : Loading a fresh vocabulary\n",
      "2018-09-08 14:48:17,119 : INFO : effective_min_count=1 retains 3167 unique words (100% of original 3167, drops 0)\n",
      "2018-09-08 14:48:17,120 : INFO : effective_min_count=1 leaves 1580122 word corpus (100% of original 1580122, drops 0)\n",
      "2018-09-08 14:48:17,130 : INFO : deleting the raw counts dictionary of 3167 items\n",
      "2018-09-08 14:48:17,131 : INFO : sample=0.001 downsamples 18 most-common words\n",
      "2018-09-08 14:48:17,133 : INFO : downsampling leaves estimated 1560986 word corpus (98.8% of prior 1580122)\n",
      "2018-09-08 14:48:17,142 : INFO : estimated required memory for 3167 words and 100 dimensions: 4117100 bytes\n",
      "2018-09-08 14:48:17,142 : INFO : resetting layer weights\n",
      "2018-09-08 14:48:17,189 : INFO : training model with 3 workers on 3167 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-09-08 14:48:18,198 : INFO : EPOCH 1 - PROGRESS: at 34.80% examples, 550016 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-08 14:48:19,218 : INFO : EPOCH 1 - PROGRESS: at 75.09% examples, 580143 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-08 14:48:19,767 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-08 14:48:19,788 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-08 14:48:19,808 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-08 14:48:19,809 : INFO : EPOCH - 1 : training on 1580122 raw words (1561011 effective words) took 2.6s, 596510 effective words/s\n",
      "2018-09-08 14:48:20,826 : INFO : EPOCH 2 - PROGRESS: at 38.10% examples, 593961 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-08 14:48:21,830 : INFO : EPOCH 2 - PROGRESS: at 81.67% examples, 635794 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-08 14:48:22,262 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-08 14:48:22,276 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-08 14:48:22,296 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-08 14:48:22,297 : INFO : EPOCH - 2 : training on 1580122 raw words (1560978 effective words) took 2.5s, 628097 effective words/s\n",
      "2018-09-08 14:48:23,369 : INFO : EPOCH 3 - PROGRESS: at 40.42% examples, 600737 words/s, in_qsize 4, out_qsize 2\n",
      "2018-09-08 14:48:24,383 : INFO : EPOCH 3 - PROGRESS: at 84.98% examples, 639927 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-08 14:48:24,678 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-08 14:48:24,704 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-08 14:48:24,714 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-08 14:48:24,716 : INFO : EPOCH - 3 : training on 1580122 raw words (1560958 effective words) took 2.4s, 646471 effective words/s\n",
      "2018-09-08 14:48:25,727 : INFO : EPOCH 4 - PROGRESS: at 38.58% examples, 607841 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-08 14:48:26,742 : INFO : EPOCH 4 - PROGRESS: at 81.16% examples, 629326 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-08 14:48:27,107 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-08 14:48:27,129 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-08 14:48:27,145 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-08 14:48:27,147 : INFO : EPOCH - 4 : training on 1580122 raw words (1561019 effective words) took 2.4s, 642996 effective words/s\n",
      "2018-09-08 14:48:28,158 : INFO : EPOCH 5 - PROGRESS: at 39.88% examples, 627886 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-08 14:48:29,166 : INFO : EPOCH 5 - PROGRESS: at 81.16% examples, 631972 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-08 14:48:29,536 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-08 14:48:29,555 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-08 14:48:29,572 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-08 14:48:29,573 : INFO : EPOCH - 5 : training on 1580122 raw words (1561015 effective words) took 2.4s, 644691 effective words/s\n",
      "2018-09-08 14:48:29,573 : INFO : training on a 7900610 raw words (7804981 effective words) took 12.4s, 630266 effective words/s\n",
      "2018-09-08 14:48:29,576 : INFO : saving Word2Vec object under item2vec.model, separately None\n",
      "2018-09-08 14:48:29,577 : INFO : not storing attribute vectors_norm\n",
      "2018-09-08 14:48:29,579 : INFO : not storing attribute cum_table\n",
      "2018-09-08 14:48:29,613 : INFO : saved item2vec.model\n"
     ]
    }
   ],
   "source": [
    "# Open data file\n",
    "file = open('./dataset/yes_i2v/train2.txt','r')\n",
    "playlists = word2vec.LineSentence(file)\n",
    "\n",
    "#\n",
    "path = get_tmpfile(\"item2vec.model\")\n",
    "    \n",
    "# Modelling\n",
    "model = word2vec.Word2Vec(playlists, sg=1, min_count=1, window=5, iter=5, size=100)\n",
    "model.save(\"item2vec.model\")\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting similar items by name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Development\\Anaconda3\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('3027', 0.9957987666130066),\n",
       " ('1107', 0.9955244064331055),\n",
       " ('2610', 0.995013952255249),\n",
       " ('2801', 0.9947564601898193),\n",
       " ('1106', 0.9944981336593628),\n",
       " ('1110', 0.9943162202835083),\n",
       " ('3028', 0.9933587908744812),\n",
       " ('1077', 0.9925479888916016),\n",
       " ('3115', 0.9919270277023315),\n",
       " ('1108', 0.9911092519760132),\n",
       " ('1103', 0.990796685218811),\n",
       " ('1062', 0.9907141923904419),\n",
       " ('1079', 0.9899793863296509),\n",
       " ('2777', 0.9891980886459351),\n",
       " ('1070', 0.9886375665664673),\n",
       " ('1072', 0.9883439540863037),\n",
       " ('1041', 0.9868121147155762),\n",
       " ('1087', 0.9846866726875305),\n",
       " ('105', 0.9842161536216736),\n",
       " ('1066', 0.9839122295379639)]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_word('3029', topn =20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Development\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           x         y\n",
      "0 -48.885067  5.443846\n",
      "1 -44.316376 -5.828230\n",
      "2 -52.608604  2.166635\n",
      "3 -48.853947 -2.362439\n",
      "4 -49.298435 -2.150290\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "\n",
    "vocab = list(model.wv.vocab)\n",
    "X = model[vocab]\n",
    "\n",
    "tsne = TSNE(n_components=2)\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "\n",
    "df = pd.DataFrame(X_tsne, index=vocab, columns=['x', 'y'])\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              x         y\n",
      "3    -48.853947 -2.362439\n",
      "1744 -42.078548  1.058095\n",
      "79   -42.875626 -5.258737\n"
     ]
    }
   ],
   "source": [
    "# Representative points\n",
    "# usher\n",
    "df2 = df.loc[['3', '1744','79']]\n",
    "\n",
    "# Guns'n rose\n",
    "df3 = df.loc[['318', '365','314']]\n",
    "\n",
    "# Bob Marley\n",
    "df4 = df.loc[['1040', '3029','1110']]\n",
    "\n",
    "# Fall out boys\n",
    "df5 = df.loc[['2641', '2966','2348']]\n",
    "\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "x   -48.853947\n",
      "y    -2.362439\n",
      "Name: 3, dtype: float32\n",
      "x   -42.078548\n",
      "y     1.058095\n",
      "Name: 1744, dtype: float32\n",
      "x   -42.875626\n",
      "y    -5.258737\n",
      "Name: 79, dtype: float32\n",
      "x    23.850960\n",
      "y   -36.922859\n",
      "Name: 318, dtype: float32\n",
      "x    28.731955\n",
      "y   -40.050190\n",
      "Name: 365, dtype: float32\n",
      "x    28.174059\n",
      "y   -15.112495\n",
      "Name: 314, dtype: float32\n",
      "x    -1.294396\n",
      "y    64.735275\n",
      "Name: 1040, dtype: float32\n",
      "x     4.238662\n",
      "y    70.469826\n",
      "Name: 3029, dtype: float32\n",
      "x     5.145927\n",
      "y    71.447586\n",
      "Name: 1110, dtype: float32\n",
      "x   -19.509104\n",
      "y    -8.304080\n",
      "Name: 2641, dtype: float32\n",
      "x   -15.760060\n",
      "y   -12.127275\n",
      "Name: 2966, dtype: float32\n",
      "x   -19.897903\n",
      "y    -9.086158\n",
      "Name: 2348, dtype: float32\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "x = df['x']\n",
    "y = df['y']\n",
    "\n",
    "# Calculate the point density\n",
    "xy = np.vstack([x,y])\n",
    "z = gaussian_kde(xy)(xy)\n",
    "\n",
    "# Plot a scatter\n",
    "ax.scatter(x, y, c=z, s=10, edgecolor='')\n",
    "\n",
    "#\n",
    "for i,pos in df2.iterrows():\n",
    "    print(pos)\n",
    "    ax.plot(pos[0],pos[1],'m^')\n",
    "\n",
    "#\n",
    "for i,pos in df3.iterrows():\n",
    "    print(pos)\n",
    "    ax.plot(pos[0],pos[1],'bv')\n",
    "    \n",
    "#\n",
    "for i,pos in df4.iterrows():\n",
    "    print(pos)\n",
    "    ax.plot(pos[0],pos[1],'yD')\n",
    "\n",
    "#\n",
    "for i,pos in df5.iterrows():\n",
    "    print(pos)\n",
    "    ax.plot(pos[0],pos[1],'rx')\n",
    "    \n",
    "# # Show annotating of items in df2\n",
    "# for word, pos in df2.iterrows():\n",
    "#     ax.annotate(word, pos)\n",
    "# for word, pos in df3.iterrows():\n",
    "#     ax.annotate(word, pos)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use of genre data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-08 14:48:38,707 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Num                                         Music Name      Artist  \\\n",
      "0    0                       Gucci Time (w\\/ Swizz Beatz)  Gucci Mane   \n",
      "1    1  Aston Martin Music (w\\/ Drake & Chrisette Mich...   Rick Ross   \n",
      "2    2                      Get Back Up (w\\/ Chris Brown)        T.I.   \n",
      "3    3                 Hot Toddy (w\\/ Jay-Z & Ester Dean)       Usher   \n",
      "4    4                                       Whip My Hair      Willow   \n",
      "\n",
      "                                             Tags  \n",
      "0                                         115 173  \n",
      "1      14 27 62 88 90 110 115 123 155 173 190 214  \n",
      "2                                         115 173  \n",
      "3                                        2 72 173  \n",
      "4  2 6 24 52 62 72 88 107 115 126 141 155 173 190   \n",
      "\n",
      "Searching Music:  1040 \t Three Little Birds \t Bob Marley & The Wailers \n",
      "\n",
      "Similar Music:  Buffalo Soldier \t Bob Marley & The Wailers\n",
      "('1083', 0.989186704158783)\n",
      "Similar Music:  Is This Love? \t Bob Marley & The Wailers\n",
      "('1099', 0.9883902668952942)\n",
      "Similar Music:  Stir It Up \t Bob Marley & The Wailers\n",
      "('1081', 0.9794403314590454)\n",
      "Similar Music:  Get Up, Stand Up \t Bob Marley & The Wailers\n",
      "('1098', 0.9785326719284058)\n",
      "Similar Music:  One Love \\/ People Get Ready \t Bob Marley & The Wailers\n",
      "('1059', 0.9760600328445435)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Development\\Anaconda3\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "import pandas as pd\n",
    "\n",
    "df_sum = pd.read_table(\"./dataset/yes_i2v/summary.txt\", delimiter='\\t', header=None, names=('Num', 'Music Name', 'Artist', 'Tags'))\n",
    "print(df_sum.head(),'\\n')\n",
    "\n",
    "# Print similiraties by number of music\n",
    "def print_simi(music_num):\n",
    "    simi_list = model.wv.similar_by_word(str(music_num), topn =5)\n",
    "    print(\"Searching Music: \",music_num, '\\t',df_sum.iat[music_num, 1], '\\t',df_sum.iat[music_num, 2], \"\\n\")\n",
    "    for l in simi_list:\n",
    "        print(\"Similar Music: \", df_sum.iat[int(l[0]), 1], '\\t',df_sum.iat[int(l[0]), 2])\n",
    "        print(l)\n",
    "\n",
    "        \n",
    "print_simi(1040)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['88', '6', '52', '56', '62', '66', '98', '106', '115', '148', '173', '50', '62', '72', '88', '90', '98', '115', '115', '173', '250'] \n",
      "\n",
      "([('115', 3), ('88', 2), ('62', 2), ('98', 2)], [' wjlb-fm', ' hip hop', ' rnb', ' r&b'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Development\\Anaconda3\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([('115', 3), ('88', 2), ('62', 2)], [' wjlb-fm', ' hip hop', ' rnb'])"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "df_tag = pd.read_table(\"./dataset/yes_small/tag_hash.txt\", delimiter=',', header=None, names=('Num', 'Tag'))\n",
    "\n",
    "# Get tags of all of five similar musics\n",
    "def get_tags(music_num):\n",
    "    simi_list = model.wv.similar_by_word(str(music_num), topn =5)\n",
    "    tags = []\n",
    "    for l in simi_list:\n",
    "        tags_str = df_sum.iat[int(l[0]), 3]\n",
    "        tags_list = tags_str.split()\n",
    "        for i in tags_list:\n",
    "            tags.append(i)\n",
    "    return(tags)\n",
    "    \n",
    "print(get_tags(8),'\\n')\n",
    "\n",
    "# Get top n of common tags in five similar musics\n",
    "def top_n_tags(music_num, topn=3):\n",
    "    tags = get_tags(music_num)\n",
    "    tags_counts = Counter(tags)\n",
    "    top_n = tags_counts.most_common(topn)\n",
    "    top_n_tag_name = []\n",
    "    for i in top_n:\n",
    "        top_n_tag_name.append(df_tag.iat[int(i[0]),1])\n",
    "#         print(df_tag.iat[int(i[0]),1])\n",
    "#     for j in top_n:\n",
    "#         times.append(j[1])\n",
    "    return top_n, top_n_tag_name\n",
    "\n",
    "print(top_n_tags(8,topn=4))  \n",
    "top_n_tags(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching Music:  11 \t DJ Got Us Fallin' In Love (w\\/ Pitbull) \t Usher \n",
      "\n",
      "Similar Music:  OMG (w\\/ Will.I.Am) \t Usher\n",
      "('43', 0.902180016040802)\n",
      "Similar Music:  Airplanes (w\\/ Hayley Williams) \t B.o.B\n",
      "('47', 0.862022876739502)\n",
      "Similar Music:  No Love (w\\/ Lil Wayne) \t Eminem\n",
      "('79', 0.8565596342086792)\n",
      "Similar Music:  Imma Be \t Black Eyed Peas\n",
      "('139', 0.8550606966018677)\n",
      "Similar Music:  Ridin' Solo \t Jason DeRulo\n",
      "('72', 0.8512059450149536)\n",
      "\n",
      "\n",
      "Top N common tags:  [' pop', ' awesome', ' dance']\n",
      "Appearance times of common tags:  [5, 4, 4] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Development\\Anaconda3\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "def genre_of_simis(music_num):\n",
    "    print_simi(music_num)\n",
    "    print('\\n')\n",
    "    print(\"Top N common tags: \",top_n_tags(music_num)[1])\n",
    "    times = []\n",
    "    for i in top_n_tags(music_num)[0]:\n",
    "        times.append(i[1])\n",
    "    print(\"Appearance times of common tags: \", times,'\\n')\n",
    "    \n",
    "    \n",
    "genre_of_simis(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing rec-music's tags with searching-music's tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Development\\Anaconda3\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9093493367024637\n"
     ]
    }
   ],
   "source": [
    "def cal_common_tags(music_num):\n",
    "    tags_str = df_sum.iat[music_num, 3]\n",
    "    tags_list = tags_str.split()\n",
    "    list_a = []\n",
    "    for i in tags_list:\n",
    "        list_a.append(i)\n",
    "#     print(list_a)\n",
    "    #\n",
    "    list_b = []\n",
    "    top_n = top_n_tags(music_num, topn=5)[0]\n",
    "    for j in top_n:\n",
    "        list_b.append(j[0])\n",
    "#     print(list_b,'\\n')\n",
    "    #\n",
    "    result = list(set(list_a) & set(list_b))\n",
    "    if len(result):    # not empty\n",
    "#         print(result)\n",
    "#         print('true')\n",
    "        return 1\n",
    "    else:\n",
    "#         print('false')\n",
    "        return 0\n",
    "        \n",
    "\n",
    "def cal_acc():\n",
    "    tf_list = []\n",
    "    for i in range(0, 2015):\n",
    "#         print(i)\n",
    "        tf_list.append(cal_common_tags(i))\n",
    "    for j in range(2016, 3167):\n",
    "#         print(j)\n",
    "        tf_list.append(cal_common_tags(j))\n",
    "    total = len(tf_list)\n",
    "    right_count =[]\n",
    "    for i in tf_list:\n",
    "        if i ==1:\n",
    "            right_count.append(i)\n",
    "    right = len(right_count)\n",
    "    print(right/total)\n",
    "\n",
    "    \n",
    "cal_acc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "item2vec",
   "language": "python",
   "name": "item2vec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
